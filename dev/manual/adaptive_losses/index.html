<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Adaptive Loss Functions · NeuralPDE.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://docs.sciml.ai/NeuralPDE/stable/manual/adaptive_losses/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralPDE.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralPDE.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralPDE.jl: Automatic Physics-Informed Neural Networks (PINNs)</a></li><li><span class="tocitem">ODE PINN Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/ode/">Introduction to NeuralPDE for ODEs</a></li></ul></li><li><span class="tocitem">PDE PINN Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/pdesystem/">Introduction to NeuralPDE for PDEs</a></li><li><a class="tocitem" href="../../tutorials/gpu/">Using GPUs</a></li><li><a class="tocitem" href="../../tutorials/systems/">Defining Systems of PDEs</a></li><li><a class="tocitem" href="../../tutorials/constraints/">Imposing Constraints</a></li><li><a class="tocitem" href="../../tutorials/low_level/">The symbolic_discretize Interface</a></li><li><a class="tocitem" href="../../tutorials/param_estim/">Optimising Parameters (Solving Inverse Problems)</a></li><li><a class="tocitem" href="../../tutorials/integro_diff/">Solving Integro Differential Equations</a></li><li><a class="tocitem" href="../../tutorials/neural_adapter/">Transfer Learning with Neural Adapter</a></li><li><a class="tocitem" href="../../tutorials/derivative_neural_network/">The Derivative Neural Network Approximation</a></li></ul></li><li><span class="tocitem">Extended Examples</span><ul><li><a class="tocitem" href="../../examples/wave/">1D Wave Equation with Dirichlet boundary conditions</a></li><li><a class="tocitem" href="../../examples/3rd/">ODE with a 3rd-Order Derivative</a></li><li><a class="tocitem" href="../../examples/ks/">Kuramoto–Sivashinsky equation</a></li><li><a class="tocitem" href="../../examples/heterogeneous/">PDEs with Dependent Variables on Heterogeneous Domains</a></li><li><a class="tocitem" href="../../examples/linear_parabolic/">Linear parabolic system of PDEs</a></li><li><a class="tocitem" href="../../examples/nonlinear_elliptic/">Nonlinear elliptic system of PDEs</a></li><li><a class="tocitem" href="../../examples/nonlinear_hyperbolic/">Nonlinear hyperbolic system of PDEs</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../ode/">ODE-Specialized Physics-Informed Neural Network (PINN) Solver</a></li><li><a class="tocitem" href="../pinns/"><code>PhysicsInformedNN</code> Discretizer for PDESystems</a></li><li><a class="tocitem" href="../training_strategies/">Training Strategies</a></li><li class="is-active"><a class="tocitem" href>Adaptive Loss Functions</a></li><li><a class="tocitem" href="../logging/">Logging Utilities</a></li><li><a class="tocitem" href="../neural_adapters/">Transfer Learning with neural_adapter</a></li></ul></li><li><span class="tocitem">Developer Documentation</span><ul><li><a class="tocitem" href="../../developer/debugging/">Debugging PINN Solutions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Adaptive Loss Functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Adaptive Loss Functions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/NeuralPDE.jl/blob/master/docs/src/manual/adaptive_losses.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="adaptive_loss"><a class="docs-heading-anchor" href="#adaptive_loss">Adaptive Loss Functions</a><a id="adaptive_loss-1"></a><a class="docs-heading-anchor-permalink" href="#adaptive_loss" title="Permalink"></a></h1><p>The NeuralPDE <code>discretize</code> function allows for specifying adaptive loss function strategy which improve training performance by reweighing the equations as necessary to ensure the boundary conditions are well-satisfied, even in ill-conditioned scenarios. The following are the options for the <code>adaptive_loss</code>:</p><article class="docstring"><header><a class="docstring-binding" id="NeuralPDE.NonAdaptiveLoss" href="#NeuralPDE.NonAdaptiveLoss"><code>NeuralPDE.NonAdaptiveLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NonAdaptiveLoss{T}(; pde_loss_weights = 1,
                     bc_loss_weights = 1,
                     additional_loss_weights = 1)</code></pre><p>A way of loss weighting the components of the loss function in the total sum that does not change during optimization</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralPDE.jl/blob/aa21202c4bde9d2e3519b1fa8375450b8ff709b9/src/adaptive_losses.jl#L15-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralPDE.GradientScaleAdaptiveLoss" href="#NeuralPDE.GradientScaleAdaptiveLoss"><code>NeuralPDE.GradientScaleAdaptiveLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GradientScaleAdaptiveLoss(reweight_every;
                          weight_change_inertia = 0.9,
                          pde_loss_weights = 1,
                          bc_loss_weights = 1,
                          additional_loss_weights = 1)</code></pre><p>A way of adaptively reweighting the components of the loss function in the total sum such that BC<em>i loss weights are scaled by the exponential moving average of max(|∇pde</em>loss|)/mean(|∇bc<em>i</em>loss|) )</p><p><strong>Positional Arguments</strong></p><ul><li><code>reweight_every</code>: how often to reweight the BC loss functions, measured in iterations. Reweighting is somewhat expensive since it involves evaluating the gradient of each component loss function,</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>weight_change_inertia</code>: a real number that represents the inertia of the exponential moving average of the BC weight changes,</li></ul><p><strong>References</strong></p><p>Understanding and mitigating gradient pathologies in physics-informed neural networks Sifan Wang, Yujun Teng, Paris Perdikaris https://arxiv.org/abs/2001.04536v1</p><p>With code reference: https://github.com/PredictiveIntelligenceLab/GradientPathologiesPINNs</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralPDE.jl/blob/aa21202c4bde9d2e3519b1fa8375450b8ff709b9/src/adaptive_losses.jl#L56-L88">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralPDE.MiniMaxAdaptiveLoss" href="#NeuralPDE.MiniMaxAdaptiveLoss"><code>NeuralPDE.MiniMaxAdaptiveLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">function MiniMaxAdaptiveLoss(reweight_every;
                             pde_max_optimiser = Flux.ADAM(1e-4),
                             bc_max_optimiser = Flux.ADAM(0.5),
                             pde_loss_weights = 1,
                             bc_loss_weights = 1,
                             additional_loss_weights = 1)</code></pre><p>A way of adaptively reweighting the components of the loss function in the total sum such that the loss weights are maximized by an internal optimizer, which leads to a behavior where loss functions that have not been satisfied get a greater weight,</p><p><strong>Positional Arguments</strong></p><ul><li><code>reweight_every</code>: how often to reweight the PDE and BC loss functions, measured in iterations.  Reweighting is cheap since it re-uses the value of loss functions generated during the main optimization loop.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>pde_max_optimiser</code>: a Flux.Optimise.AbstractOptimiser that is used internally to maximize the weights of the PDE loss functions.</li><li><code>bc_max_optimiser</code>: a Flux.Optimise.AbstractOptimiser that is used internally to maximize the weights of the BC loss functions.</li></ul><p><strong>References</strong></p><p>Self-Adaptive Physics-Informed Neural Networks using a Soft Attention Mechanism Levi McClenny, Ulisses Braga-Neto https://arxiv.org/abs/2009.04544</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralPDE.jl/blob/aa21202c4bde9d2e3519b1fa8375450b8ff709b9/src/adaptive_losses.jl#L159-L191">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../training_strategies/">« Training Strategies</a><a class="docs-footer-nextpage" href="../logging/">Logging Utilities »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Saturday 1 April 2023 19:33">Saturday 1 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
