<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Defining Systems of PDEs · NeuralPDE.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://docs.sciml.ai/NeuralPDE/stable/tutorials/systems/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralPDE.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralPDE.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralPDE.jl: Automatic Physics-Informed Neural Networks (PINNs)</a></li><li><span class="tocitem">ODE PINN Tutorials</span><ul><li><a class="tocitem" href="../ode/">Introduction to NeuralPDE for ODEs</a></li><li><a class="tocitem" href="../../examples/Lotka_Volterra_BPINNs/">Bayesian PINNs for Coupled ODEs - Lotka-Volterra</a></li></ul></li><li><span class="tocitem">PDE PINN Tutorials</span><ul><li><a class="tocitem" href="../pdesystem/">Introduction to NeuralPDE for PDEs</a></li><li><a class="tocitem" href="../gpu/">Using GPUs</a></li><li class="is-active"><a class="tocitem" href>Defining Systems of PDEs</a><ul class="internal"><li><a class="tocitem" href="#Solution"><span>Solution</span></a></li><li><a class="tocitem" href="#Direct-Construction-via-symbolic_discretize"><span>Direct Construction via symbolic_discretize</span></a></li><li><a class="tocitem" href="#Solution-Representation"><span>Solution Representation</span></a></li></ul></li><li><a class="tocitem" href="../constraints/">Imposing Constraints</a></li><li><a class="tocitem" href="../low_level/">The symbolic_discretize Interface</a></li><li><a class="tocitem" href="../param_estim/">Optimising Parameters (Solving Inverse Problems)</a></li><li><a class="tocitem" href="../integro_diff/">Solving Integro Differential Equations</a></li><li><a class="tocitem" href="../neural_adapter/">Transfer Learning with Neural Adapter</a></li><li><a class="tocitem" href="../derivative_neural_network/">The Derivative Neural Network Approximation</a></li></ul></li><li><span class="tocitem">Extended Examples</span><ul><li><a class="tocitem" href="../../examples/wave/">1D Wave Equation with Dirichlet boundary conditions</a></li><li><a class="tocitem" href="../../examples/3rd/">ODE with a 3rd-Order Derivative</a></li><li><a class="tocitem" href="../../examples/ks/">Kuramoto–Sivashinsky equation</a></li><li><a class="tocitem" href="../../examples/heterogeneous/">PDEs with Dependent Variables on Heterogeneous Domains</a></li><li><a class="tocitem" href="../../examples/linear_parabolic/">Linear parabolic system of PDEs</a></li><li><a class="tocitem" href="../../examples/nonlinear_elliptic/">Nonlinear elliptic system of PDEs</a></li><li><a class="tocitem" href="../../examples/nonlinear_hyperbolic/">Nonlinear hyperbolic system of PDEs</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../../manual/ode/">ODE-Specialized Physics-Informed Neural Network (PINN) Solver</a></li><li><a class="tocitem" href="../../manual/pinns/"><code>PhysicsInformedNN</code> Discretizer for PDESystems</a></li><li><a class="tocitem" href="../../manual/training_strategies/">Training Strategies</a></li><li><a class="tocitem" href="../../manual/adaptive_losses/">Adaptive Loss Functions</a></li><li><a class="tocitem" href="../../manual/logging/">Logging Utilities</a></li><li><a class="tocitem" href="../../manual/neural_adapters/">Transfer Learning with neural_adapter</a></li></ul></li><li><span class="tocitem">Developer Documentation</span><ul><li><a class="tocitem" href="../../developer/debugging/">Debugging PINN Solutions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">PDE PINN Tutorials</a></li><li class="is-active"><a href>Defining Systems of PDEs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Defining Systems of PDEs</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/NeuralPDE.jl/blob/master/docs/src/tutorials/systems.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="systems"><a class="docs-heading-anchor" href="#systems">Defining Systems of PDEs for Physics-Informed Neural Networks (PINNs)</a><a id="systems-1"></a><a class="docs-heading-anchor-permalink" href="#systems" title="Permalink"></a></h1><p>In this example, we will solve the PDE system:</p><p class="math-container">\[\begin{align*}
∂_t^2 u_1(t, x) &amp; = ∂_x^2 u_1(t, x) + u_3(t, x) \, \sin(\pi x) \, ,\\
∂_t^2 u_2(t, x) &amp; = ∂_x^2 u_2(t, x) + u_3(t, x) \, \cos(\pi x) \, ,\\
0 &amp; = u_1(t, x) \sin(\pi x) + u_2(t, x) \cos(\pi x) - e^{-t} \, ,
\end{align*}\]</p><p>with the initial conditions:</p><p class="math-container">\[\begin{align*}
u_1(0, x) &amp; = \sin(\pi x) \, ,\\
∂_t u_1(0, x) &amp; = - \sin(\pi x) \, ,\\
u_2(0, x) &amp; = \cos(\pi x) \, ,\\
∂_t u_2(0, x) &amp; = - \cos(\pi x) \, ,
\end{align*}\]</p><p>and the boundary conditions:</p><p class="math-container">\[\begin{align*}
u_1(t, 0) &amp; = u_1(t, 1) = 0 \, ,\\
u_2(t, 0) &amp; = - u_2(t, 1) = e^{-t} \, ,
\end{align*}\]</p><p>with physics-informed neural networks.</p><h2 id="Solution"><a class="docs-heading-anchor" href="#Solution">Solution</a><a id="Solution-1"></a><a class="docs-heading-anchor-permalink" href="#Solution" title="Permalink"></a></h2><pre><code class="language-julia hljs">using NeuralPDE, Lux, ModelingToolkit, Optimization, OptimizationOptimJL
import ModelingToolkit: Interval, infimum, supremum

@parameters t, x
@variables u1(..), u2(..), u3(..)
Dt = Differential(t)
Dtt = Differential(t)^2
Dx = Differential(x)
Dxx = Differential(x)^2

eqs = [Dtt(u1(t, x)) ~ Dxx(u1(t, x)) + u3(t, x) * sin(pi * x),
    Dtt(u2(t, x)) ~ Dxx(u2(t, x)) + u3(t, x) * cos(pi * x),
    0.0 ~ u1(t, x) * sin(pi * x) + u2(t, x) * cos(pi * x) - exp(-t)]

bcs = [u1(0, x) ~ sin(pi * x),
    u2(0, x) ~ cos(pi * x),
    Dt(u1(0, x)) ~ -sin(pi * x),
    Dt(u2(0, x)) ~ -cos(pi * x),
    u1(t, 0) ~ 0.0,
    u2(t, 0) ~ exp(-t),
    u1(t, 1) ~ 0.0,
    u2(t, 1) ~ -exp(-t)]

# Space and time domains
domains = [t ∈ Interval(0.0, 1.0),
    x ∈ Interval(0.0, 1.0)]

# Neural network
input_ = length(domains)
n = 15
chain = [Lux.Chain(Dense(input_, n, Lux.σ), Dense(n, n, Lux.σ), Dense(n, 1)) for _ in 1:3]

strategy = QuadratureTraining()
discretization = PhysicsInformedNN(chain, strategy)

@named pdesystem = PDESystem(eqs, bcs, domains, [t, x], [u1(t, x), u2(t, x), u3(t, x)])
prob = discretize(pdesystem, discretization)
sym_prob = symbolic_discretize(pdesystem, discretization)

pde_inner_loss_functions = sym_prob.loss_functions.pde_loss_functions
bcs_inner_loss_functions = sym_prob.loss_functions.bc_loss_functions

callback = function (p, l)
    println(&quot;loss: &quot;, l)
    println(&quot;pde_losses: &quot;, map(l_ -&gt; l_(p), pde_inner_loss_functions))
    println(&quot;bcs_losses: &quot;, map(l_ -&gt; l_(p), bcs_inner_loss_functions))
    return false
end

res = Optimization.solve(prob, BFGS(); callback = callback, maxiters = 5000)

phi = discretization.phi</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{NeuralPDE.Phi{Lux.Chain{NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{Lux.Dense{true, typeof(NNlib.sigmoid_fast), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}, Lux.Dense{true, typeof(NNlib.sigmoid_fast), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}, Lux.Dense{true, typeof(identity), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}}}, Nothing}, NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}}}}}:
 NeuralPDE.Phi{Lux.Chain{NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{Lux.Dense{true, typeof(NNlib.sigmoid_fast), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}, Lux.Dense{true, typeof(NNlib.sigmoid_fast), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}, Lux.Dense{true, typeof(identity), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}}}, Nothing}, NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}}}}(Chain(), (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple()))
 NeuralPDE.Phi{Lux.Chain{NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{Lux.Dense{true, typeof(NNlib.sigmoid_fast), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}, Lux.Dense{true, typeof(NNlib.sigmoid_fast), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}, Lux.Dense{true, typeof(identity), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}}}, Nothing}, NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}}}}(Chain(), (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple()))
 NeuralPDE.Phi{Lux.Chain{NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{Lux.Dense{true, typeof(NNlib.sigmoid_fast), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}, Lux.Dense{true, typeof(NNlib.sigmoid_fast), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}, Lux.Dense{true, typeof(identity), typeof(WeightInitializers.glorot_uniform), typeof(WeightInitializers.zeros32)}}}, Nothing}, NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}}}}(Chain(), (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple()))</code></pre><h2 id="Direct-Construction-via-symbolic_discretize"><a class="docs-heading-anchor" href="#Direct-Construction-via-symbolic_discretize">Direct Construction via symbolic_discretize</a><a id="Direct-Construction-via-symbolic_discretize-1"></a><a class="docs-heading-anchor-permalink" href="#Direct-Construction-via-symbolic_discretize" title="Permalink"></a></h2><p>One can take apart the pieces and reassemble the loss functions using the <code>symbolic_discretize</code> interface. Here is an example using the components from <code>symbolic_discretize</code> to fully reproduce the <code>discretize</code> optimization:</p><pre><code class="language-julia hljs">using NeuralPDE, Lux, ModelingToolkit, Optimization, OptimizationOptimJL
import ModelingToolkit: Interval, infimum, supremum

@parameters t, x
@variables u1(..), u2(..), u3(..)
Dt = Differential(t)
Dtt = Differential(t)^2
Dx = Differential(x)
Dxx = Differential(x)^2

eqs = [Dtt(u1(t, x)) ~ Dxx(u1(t, x)) + u3(t, x) * sin(pi * x),
    Dtt(u2(t, x)) ~ Dxx(u2(t, x)) + u3(t, x) * cos(pi * x),
    0.0 ~ u1(t, x) * sin(pi * x) + u2(t, x) * cos(pi * x) - exp(-t)]

bcs = [u1(0, x) ~ sin(pi * x),
    u2(0, x) ~ cos(pi * x),
    Dt(u1(0, x)) ~ -sin(pi * x),
    Dt(u2(0, x)) ~ -cos(pi * x),
    u1(t, 0) ~ 0.0,
    u2(t, 0) ~ exp(-t),
    u1(t, 1) ~ 0.0,
    u2(t, 1) ~ -exp(-t)]

# Space and time domains
domains = [t ∈ Interval(0.0, 1.0),
    x ∈ Interval(0.0, 1.0)]

# Neural network
input_ = length(domains)
n = 15
chain = [Lux.Chain(Dense(input_, n, Lux.σ), Dense(n, n, Lux.σ), Dense(n, 1)) for _ in 1:3]
@named pdesystem = PDESystem(eqs, bcs, domains, [t, x], [u1(t, x), u2(t, x), u3(t, x)])

strategy = NeuralPDE.QuadratureTraining()
discretization = PhysicsInformedNN(chain, strategy)
sym_prob = NeuralPDE.symbolic_discretize(pdesystem, discretization)

pde_loss_functions = sym_prob.loss_functions.pde_loss_functions
bc_loss_functions = sym_prob.loss_functions.bc_loss_functions

callback = function (p, l)
    println(&quot;loss: &quot;, l)
    println(&quot;pde_losses: &quot;, map(l_ -&gt; l_(p), pde_loss_functions))
    println(&quot;bcs_losses: &quot;, map(l_ -&gt; l_(p), bc_loss_functions))
    return false
end

loss_functions = [pde_loss_functions; bc_loss_functions]

function loss_function(θ, p)
    sum(map(l -&gt; l(θ), loss_functions))
end

f_ = OptimizationFunction(loss_function, Optimization.AutoZygote())
prob = Optimization.OptimizationProblem(f_, sym_prob.flat_init_params)

res = Optimization.solve(prob, OptimizationOptimJL.BFGS(); callback = callback,
                         maxiters = 5000)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">u: ComponentVector{Float64}(depvar = (u1 = (layer_1 = (weight = [0.21450980171969578 -4.13467525260995; 1.9866696092125697 -0.4790408389621914; … ; 1.048189671411811 -0.024364643185824212; 0.7231560400435189 -2.709860103111997], bias = [-0.5048108949530469; 0.2228813369049465; … ; -0.04514992520929233; 0.5178743130528893;;]), layer_2 = (weight = [-0.372353290813754 0.08057584588416346 … -0.2771615658133209 -0.10649334367272464; -0.5752435199132223 0.28762983559314603 … 0.1768059826122904 -0.17464874309065662; … ; -1.9969377822647254 -0.5782858959062935 … 0.20172457681533693 -2.2059063567696118; -2.053583101383365 -1.59433662031552 … -1.0956423573807963 -1.4036752687217722], bias = [0.17744293113239115; 0.04903986160384607; … ; 0.08924852671027522; -0.2663502380530451;;]), layer_3 = (weight = [-1.5717055143183176 1.2816624476746996 … 2.724308093562928 -2.8733387818662974], bias = [-0.624897814716564;;])), u2 = (layer_1 = (weight = [-1.6643889257564062 1.0582956113741577; 2.6214916428390236 0.15143564624260483; … ; 1.2626240407985203 -0.05341440848702306; 1.8113384974141664 1.4720618557691494], bias = [-0.6887579840158197; 2.3751241413297484; … ; -0.8928326317355246; 0.36587466640440114;;]), layer_2 = (weight = [0.17649354837475587 -0.8827173011395959 … -1.7113200913905162 -2.554896407846074; 2.3212893845852105 0.7187861040391013 … -0.17456375554395334 -0.2778118196708899; … ; 1.127569240694639 -0.5771562368106413 … -0.5938616999938461 -0.8316950430902441; -0.5919549737244165 -0.26356838199630295 … 0.18403046722384192 0.4714290434902024], bias = [-0.395981463336374; 0.7440011380453229; … ; 0.12436467450341898; 0.2999036578260624;;]), layer_3 = (weight = [-4.458420546349558 2.9217294117042196 … 2.1287802735352717 -0.6668404051501375], bias = [-0.33635118357198673;;])), u3 = (layer_1 = (weight = [0.165067458936337 -0.49690592518422333; 0.6770262298779883 0.27838486947043783; … ; -2.291664644011232 0.1587780361721845; 0.3655591924210024 0.20488875966134154], bias = [-0.20582693810229108; 0.062277751956519516; … ; -0.035558179169974176; 0.525728660281292;;]), layer_2 = (weight = [-0.21222406976718747 -0.5053805095017972 … -0.09641176210442208 0.27325485779187636; -0.3993321808534492 -0.2579443462456597 … -0.03938736962127864 0.05079557227190081; … ; 0.2776740914622265 -0.4456544115202222 … 0.17833540098771825 -0.15525473537118836; 0.39073989454041885 0.27343892454357105 … 0.2222683633184108 -0.03959550796628212], bias = [-0.3919698139711914; -0.9128710308238254; … ; 0.0896095251617218; 0.5884704492494094;;]), layer_3 = (weight = [-0.09951357366734179 -0.43405900153989085 … 3.056010259551442 0.6709934947232242], bias = [2.0277306480778647;;]))))</code></pre><h2 id="Solution-Representation"><a class="docs-heading-anchor" href="#Solution-Representation">Solution Representation</a><a id="Solution-Representation-1"></a><a class="docs-heading-anchor-permalink" href="#Solution-Representation" title="Permalink"></a></h2><p>Now let&#39;s perform some analysis for both the <code>symbolic_discretize</code> and <code>discretize</code> APIs:</p><pre><code class="language-julia hljs">using Plots

phi = discretization.phi
ts, xs = [infimum(d.domain):0.01:supremum(d.domain) for d in domains]

minimizers_ = [res.u.depvar[sym_prob.depvars[i]] for i in 1:3]

function analytic_sol_func(t, x)
    [exp(-t) * sin(pi * x), exp(-t) * cos(pi * x), (1 + pi^2) * exp(-t)]
end
u_real = [[analytic_sol_func(t, x)[i] for t in ts for x in xs] for i in 1:3]
u_predict = [[phi[i]([t, x], minimizers_[i])[1] for t in ts for x in xs] for i in 1:3]
diff_u = [abs.(u_real[i] .- u_predict[i]) for i in 1:3]
for i in 1:3
    p1 = plot(ts, xs, u_real[i], linetype = :contourf, title = &quot;u$i, analytic&quot;)
    p2 = plot(ts, xs, u_predict[i], linetype = :contourf, title = &quot;predict&quot;)
    p3 = plot(ts, xs, diff_u[i], linetype = :contourf, title = &quot;error&quot;)
    plot(p1, p2, p3)
    savefig(&quot;sol_u$i&quot;)
end</code></pre><p><img src="https://user-images.githubusercontent.com/12683885/122979254-03634e80-d3a0-11eb-985b-d3bae2dddfde.png" alt="sol_uq1"/></p><p><img src="https://user-images.githubusercontent.com/12683885/122979278-09592f80-d3a0-11eb-8fee-de3652f138d8.png" alt="sol_uq2"/></p><p><img src="https://user-images.githubusercontent.com/12683885/122979288-0e1de380-d3a0-11eb-9005-bfb501959b83.png" alt="sol_uq3"/></p><p>Notice here that the solution is represented in the <code>OptimizationSolution</code> with <code>u</code> as the parameters for the trained neural network. But, for the case where the neural network is from Lux.jl, it&#39;s given as a <code>ComponentArray</code> where <code>res.u.depvar.x</code> corresponds to the result for the neural network corresponding to the dependent variable <code>x</code>, i.e. <code>res.u.depvar.u1</code> are the trained parameters for <code>phi[1]</code> in our example. For simpler indexing, you can use <code>res.u.depvar[:u1]</code> or <code>res.u.depvar[Symbol(:u,1)]</code> as shown here.</p><p>Subsetting the array also works, but is inelegant.</p><p>(If <code>param_estim == true</code>, then <code>res.u.p</code> are the fit parameters)</p><p>If Flux.jl is used, then subsetting the array is required. This looks like:</p><pre><code class="language-julia hljs">init_params = [Flux.destructure(c)[1] for c in chain]
acum = [0; accumulate(+, length.(init_params))]
sep = [(acum[i] + 1):acum[i + 1] for i in 1:(length(acum) - 1)]
minimizers_ = [res.minimizer[s] for s in sep]</code></pre><h4 id="Note:-Solving-Matrices-of-PDEs"><a class="docs-heading-anchor" href="#Note:-Solving-Matrices-of-PDEs">Note: Solving Matrices of PDEs</a><a id="Note:-Solving-Matrices-of-PDEs-1"></a><a class="docs-heading-anchor-permalink" href="#Note:-Solving-Matrices-of-PDEs" title="Permalink"></a></h4><p>Also, in addition to vector systems, we can use the matrix form of PDEs:</p><pre><code class="language-julia hljs">using ModelingToolkit, NeuralPDE
@parameters x y
@variables u[1:2, 1:2](..)
@derivatives Dxx&#39;&#39; ~ x
@derivatives Dyy&#39;&#39; ~ y

# Initial and boundary conditions
bcs = [u[1](x, 0) ~ x, u[2](x, 0) ~ 2, u[3](x, 0) ~ 3, u[4](x, 0) ~ 4]

# matrix PDE
eqs = @. [(Dxx(u_(x, y)) + Dyy(u_(x, y))) for u_ in u] ~ -sin(pi * x) * sin(pi * y) *
                                                         [0 1; 0 1]

size(eqs)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(2, 2)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gpu/">« Using GPUs</a><a class="docs-footer-nextpage" href="../constraints/">Imposing Constraints »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Friday 6 October 2023 16:25">Friday 6 October 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
